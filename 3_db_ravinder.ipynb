{"cells":[{"cell_type":"code","source":["from pyspark import SparkContext\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom pyspark.sql import SparkSession\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import CountVectorizer\nfrom pyspark.ml.feature import Tokenizer, RegexTokenizer, NGram\nfrom pyspark.ml.feature import MinHashLSH\nimport re\n\n\nfilepath = \"/FileStore/tables/*.txt\"\n\ndef flat(pair):\n    tx = re.sub(r'\\n\\s*\\n','\\n',pair[1],re.MULTILINE)\n    tx = re.sub(\"\\n\", \"\", tx)\n    tx = re.sub(\"\\r\", \"\", tx)\n    tx = re.sub(' +', ' ', tx)\n    return [[[name for name in pair[0].split('/')][-1] ,tx]]\nspksess = SparkSession \\\n        .builder \\\n        .appName(\"LSH\") \\\n        .getOrCreate()\nspkcontx = spksess.sparkContext\n\ndf = spkcontx.wholeTextFiles(filepath).flatMap(flat)\n# try to  print(df)\ncook_book_df = df.toDF(['title','content'])\n\n#try to Tokenize df \ntok = Tokenizer(inputCol=\"content\", outputCol=\"words\")\ntokenized = tok.transform(cook_book_df)\nnewdata = tokenized.select(\"title\",\"content\", \"words\")\n\n#Fit a CountVectorizerModel\ncvec = CountVectorizer(inputCol=\"words\", outputCol=\"features\", vocabSize=50000, minDF=2)\nmod = cvec.fit(newdata)\nnewdata = mod.transform(newdata)\n\n# Fit a MinHashLSH mod \nmhash = MinHashLSH(inputCol=\"features\", outputCol=\"hashVal\", seed=12345).setNumHashTables(3)\nmod = mhash.fit(newdata)\nnewdata = mod.transform(newdata)\nprint(\"Number of Files - \")\nprint(newdata.count())\nprint(\"Data types of columns - \")\nprint(newdata.dtypes)\nnewdata.show()\n\nmatch_mx = mod.approxSimilarityJoin(newdata, newdata, 3, \"JaccardDistance\").select(col(\"datasetA.title\")\\\n                    .alias(\"Title A\"), col(\"datasetB.title\").alias(\"Title B\"),\\\n                    col(\"JaccardDistance\")).sort(desc(\"JaccardDistance\")).dropDuplicates(['JaccardDistance'])\nthreshold = 0.85\n# match_mx.show()\noccurences = match_mx.filter(match_mx['JaccardDistance'] < threshold)\n# print(occurences.count())\nprint(\"Displaying occurences' having JaccardDistance < 0.9\")\noccurences.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Number of Files - \n76\nData types of columns - \n[(&apos;title&apos;, &apos;string&apos;), (&apos;content&apos;, &apos;string&apos;), (&apos;words&apos;, &apos;array&lt;string&gt;&apos;), (&apos;features&apos;, &apos;vector&apos;), (&apos;hashVal&apos;, &apos;array&lt;vector&gt;&apos;)]\n+--------+--------------------+--------------------+--------------------+--------------------+\n   title|             content|               words|            features|             hashVal|\n+--------+--------------------+--------------------+--------------------+--------------------+\namem.txt| The American Mat...|[, the, american,...|(50000,[0,1,2,3,9...|[[4.8538975E7], [...|\namwh.txt| The American Wom...|[, the, american,...|(50000,[0,1,2,3,4...|[[146316.0], [568...|\narmy.txt| Manual For Army ...|[, manual, for, a...|(50000,[0,1,2,3,4...|[[106485.0], [430...|\naunt.txt| &quot;Aunt Babette&apos;s&quot;...|[, &quot;aunt, babette...|(50000,[0,1,2,3,4...|[[294644.0], [659...|\nbart.txt| THE IDEAL BARTEN...|[, the, ideal, ba...|(50000,[0,1,2,3,4...|[[482803.0], [558...|\nbeec.txt| A bookplate illu...|[, a, bookplate, ...|(50000,[0,1,2,3,4...|[[146316.0], [568...|\nblue.txt| THE BLUE GRASS C...|[, the, blue, gra...|(50000,[0,1,2,3,4...|[[294644.0], [659...|\nbost.txt| THE BOSTON COOKI...|[, the, boston, c...|(50000,[0,1,2,3,4...|[[72152.0], [9976...|\nbrkf.txt| Breakfast, Lunch...|[, breakfast,, lu...|(50000,[0,1,2,3,4...|[[106485.0], [157...|\nbuck.txt| Practical Housek...|[, practical, hou...|(50000,[0,1,2,3,4...|[[294644.0], [138...|\ncclu.txt| Cooking in old C...|[, cooking, in, o...|(50000,[0,1,2,3,4...|[[32321.0], [1333...|\nchas.txt| Dr. Chase&apos;s Reci...|[, dr., chase&apos;s, ...|(50000,[0,1,2,3,4...|[[294644.0], [157...|\nchin.txt| Chinese-Japanese...|[, chinese-japane...|(50000,[0,1,2,3,4...|[[482803.0], [329...|\nchoc.txt| Chocolate and Co...|[, chocolate, and...|(50000,[0,1,2,3,4...|[[482803.0], [997...|\ncomm.txt| Common Sense in ...|[, common, sense,...|(50000,[0,1,2,3,4...|[[106485.0], [568...|\nconf.txt| The Complete Con...|[, the, complete,...|(50000,[0,1,2,3,4...|[[482803.0], [157...|\ncoow.txt| The Cook&apos;s Own B...|[, the, cook&apos;s, o...|(50000,[0,1,2,3,4...|[[482803.0], [157...|\ncreo.txt| La Cuisine Creol...|[, la, cuisine, c...|(50000,[0,1,2,3,4...|[[294644.0], [430...|\ndcvb.txt| Directions for C...|[, directions, fo...|(50000,[0,1,2,3,4...|[[482803.0], [430...|\ndish.txt| Dishes &amp;amp; Bev...|[, dishes, &amp;amp;,...|(50000,[0,1,2,3,4...|[[72152.0], [1575...|\n+--------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 20 rows\n\nDisplaying occurences&apos; having JaccardDistance &lt; 0.9\n</div>"]}}],"execution_count":1}],"metadata":{"name":"3_db_ravinder","notebookId":3253569979738954},"nbformat":4,"nbformat_minor":0}
