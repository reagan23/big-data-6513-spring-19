from pyspark import SparkContext
from pyspark.sql import SQLContext
from pyspark import HiveContext
from pyspark .sql.window import Window
import pyspark.sql.functions as func
# import pandas as pd

sc = SparkContext()
sqlContext = SQLContext(sc)
df = sqlContext.read.format("com.databricks.spark.csv").option("header", "true").option("inferschema", "true").option("delimiter", "\t").load("Sunspots.csv")
# df.show()
def moving_avg(data):
    windowspec = Window.orderBy(func.col("Months").cast('long')).rangeBetween(-1, 1)
    data.withColumn("rolling avaerga",func.avg("Sunspots").over(windowspec)).show()


moving_avg(df)